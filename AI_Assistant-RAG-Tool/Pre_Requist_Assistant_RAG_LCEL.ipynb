{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aebba4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY: AIzaSyBy...\n",
      "TAVILY_API_KEY: tvly-dev...\n",
      "GROQ_API_KEY: gsk_Znmv...\n",
      "LANGCHAIN_API_KEY: lsv2_pt_...\n",
      "LANGCHAIN_PROJECT: prequist-langgraph\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Read from .env\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "\n",
    "# Assign back into os.environ (ensures consistency for libraries)\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = LANGCHAIN_PROJECT\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "\n",
    "# Debug check\n",
    "print(\"GOOGLE_API_KEY:\", GOOGLE_API_KEY[:8] + \"...\" if GOOGLE_API_KEY else \"❌ MISSING\")\n",
    "print(\"TAVILY_API_KEY:\", TAVILY_API_KEY[:8] + \"...\" if TAVILY_API_KEY else \"❌ MISSING\")\n",
    "print(\"GROQ_API_KEY:\", GROQ_API_KEY[:8] + \"...\" if GROQ_API_KEY else \"❌ MISSING\")\n",
    "print(\"LANGCHAIN_API_KEY:\", LANGCHAIN_API_KEY[:8] + \"...\" if LANGCHAIN_API_KEY else \"❌ MISSING\")\n",
    "print(\"LANGCHAIN_PROJECT:\", LANGCHAIN_PROJECT if LANGCHAIN_PROJECT else \"❌ MISSING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5601dc7d",
   "metadata": {},
   "source": [
    "# Simple Ai Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f16ac",
   "metadata": {},
   "source": [
    "#### Using Google Generative AI with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54563451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I am a large language model, trained by Google.  I don't have a name, feelings, or personal experiences.  My purpose is to process information and respond to a wide range of prompts and questions in a helpful and informative way.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    ")\n",
    "\n",
    "query = input(\"Type your question (or 'exit'): \")\n",
    "if query.lower() != \"exit\":\n",
    "    response = llm.invoke(query)\n",
    "    print(\"Response:\", response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399005f0",
   "metadata": {},
   "source": [
    "#### Using Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446c8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: llama-3.1-8b-instant\n",
      "Response: I'm an artificial intelligence model known as a Large Language Model (LLM). I'm a computer program designed to understand and generate human-like text. I'm here to assist and communicate with you in a helpful and informative way.\n",
      "\n",
      "I don't have a personal identity, emotions, or consciousness like a human being. I exist solely to provide information, answer questions, and engage in conversations based on my training data.\n",
      "\n",
      "I'm constantly learning and improving my responses based on the interactions I have with users like you. My goal is to provide accurate, helpful, and engaging information to the best of my abilities.\n",
      "\n",
      "So, who am I? I'm a helpful AI assistant, here to assist you with any questions or topics you'd like to discuss!\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model=\"llama-3.1-8b-instant\"\n",
    ")\n",
    "\n",
    "query = input(\"Type your question (or 'exit'): \")\n",
    "if query.lower() != \"exit\":\n",
    "    response = llm.invoke(query)\n",
    "    print(\"Response:\", response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
