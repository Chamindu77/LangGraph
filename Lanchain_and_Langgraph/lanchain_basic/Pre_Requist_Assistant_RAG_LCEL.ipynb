{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aebba4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY: AIzaSyBy...\n",
      "TAVILY_API_KEY: tvly-dev...\n",
      "GROQ_API_KEY: gsk_Znmv...\n",
      "LANGCHAIN_API_KEY: lsv2_pt_...\n",
      "LANGCHAIN_PROJECT: prequist-langgraph\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Read from .env\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "\n",
    "# Assign back into os.environ (ensures consistency for libraries)\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = LANGCHAIN_PROJECT\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "\n",
    "# Debug check\n",
    "print(\"GOOGLE_API_KEY:\", GOOGLE_API_KEY[:8] + \"...\" if GOOGLE_API_KEY else \"❌ MISSING\")\n",
    "print(\"TAVILY_API_KEY:\", TAVILY_API_KEY[:8] + \"...\" if TAVILY_API_KEY else \"❌ MISSING\")\n",
    "print(\"GROQ_API_KEY:\", GROQ_API_KEY[:8] + \"...\" if GROQ_API_KEY else \"❌ MISSING\")\n",
    "print(\"LANGCHAIN_API_KEY:\", LANGCHAIN_API_KEY[:8] + \"...\" if LANGCHAIN_API_KEY else \"❌ MISSING\")\n",
    "print(\"LANGCHAIN_PROJECT:\", LANGCHAIN_PROJECT if LANGCHAIN_PROJECT else \"❌ MISSING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5601dc7d",
   "metadata": {},
   "source": [
    "# Simple Ai Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f16ac",
   "metadata": {},
   "source": [
    "#### Using Google Generative AI with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54563451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\AI\\LangGraph\\AI_Assistant-RAG-Tool\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Hi there! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    ")\n",
    "\n",
    "query = input(\"Type your question (or 'exit'): \")\n",
    "if query.lower() != \"exit\":\n",
    "    response = llm.invoke(query)\n",
    "    print(\"Response:\", response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399005f0",
   "metadata": {},
   "source": [
    "#### Using Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446c8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: llama-3.1-8b-instant\n",
      "Response: I'm an artificial intelligence model known as a Large Language Model (LLM). I'm a computer program designed to understand and generate human-like text. I'm here to assist and communicate with you in a helpful and informative way.\n",
      "\n",
      "I don't have a personal identity, emotions, or consciousness like a human being. I exist solely to provide information, answer questions, and engage in conversations based on my training data.\n",
      "\n",
      "I'm constantly learning and improving my responses based on the interactions I have with users like you. My goal is to provide accurate, helpful, and engaging information to the best of my abilities.\n",
      "\n",
      "So, who am I? I'm a helpful AI assistant, here to assist you with any questions or topics you'd like to discuss!\n"
     ]
    }
   ],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "\n",
    "# llm = ChatGroq(\n",
    "#     groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "#     model=\"llama-3.1-8b-instant\"\n",
    "# )\n",
    "\n",
    "# query = input(\"Type your question (or 'exit'): \")\n",
    "# if query.lower() != \"exit\":\n",
    "#     response = llm.invoke(query)\n",
    "#     print(\"Response:\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb23ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7090610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e33e5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88f6b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"firstchat\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ecbd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory=RunnableWithMessageHistory(llm,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac722b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Chamindu!  How can I help you today?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke((\"Hi! I'm chamindu\"),config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20f3cf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Chamindu.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke((\"tell me what is my name?\"),config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f37a141a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstchat': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm chamindu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hi Chamindu!  How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--569b7adc-b26d-4538-8859-d5d63a7e796b-0', usage_metadata={'input_tokens': 8, 'output_tokens': 14, 'total_tokens': 22, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='tell me what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Chamindu.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--e038bb17-1847-4c70-b00c-12aa9221e5ad-0', usage_metadata={'input_tokens': 28, 'output_tokens': 8, 'total_tokens': 36, 'input_token_details': {'cache_read': 0}})])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c20377",
   "metadata": {},
   "source": [
    "# RAG-LCEL Pre-requisite Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d86b15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough , RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "### Reading the txt files from source directory\n",
    "\n",
    "loader = DirectoryLoader('data', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "### Creating Chunks using RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]\n",
    "\n",
    "###  BGE Embddings\n",
    "\n",
    "'''from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "'''\n",
    "\n",
    "### Creating Retriever using Vector DB\n",
    "\n",
    "db = Chroma.from_documents(new_docs, embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dac4e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cff0c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "088f8f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, Llama 3 is a model with at least one 8B parameter version.  Three important points are:\n",
      "\n",
      "1. It has an 8B parameter version.\n",
      "2. It was released in April 2024.\n",
      "3.  It is used by at least two services (mentioned only as \"Both services\").\n"
     ]
    }
   ],
   "source": [
    "question =\"what is llama3? can you highlight 3 important points?\"\n",
    "print(retrieval_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01275dc5",
   "metadata": {},
   "source": [
    "# Tools and Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c67e86d",
   "metadata": {},
   "source": [
    "### Wikipedia search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79fc9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bcc2a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=4, doc_content_chars_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "803a0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7e0e575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78090dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad989de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'query to look up on wikipedia',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fa96da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.return_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e75a9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of \n"
     ]
    }
   ],
   "source": [
    "print(tool.run({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb8f55ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63dd210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# Define args schema correctly\n",
    "class WikiInputs(BaseModel):\n",
    "    query: str = Field(..., description=\"The search query for Wikipedia\")\n",
    "\n",
    "# Initialize the API wrapper\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "\n",
    "# Create the tool\n",
    "tool = WikipediaQueryRun(\n",
    "    name=\"wiki-tool\",\n",
    "    description=\"Look up things in Wikipedia\",\n",
    "    args_schema=WikiInputs,  \n",
    "    api_wrapper=api_wrapper,\n",
    "    return_direct=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77761d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki-tool\n",
      "Look up things in Wikipedia\n",
      "<class '__main__.WikiInputs'>\n",
      "wiki_client=<module 'wikipedia' from 'd:\\\\Project\\\\AI\\\\LangGraph\\\\AI_Assistant-RAG-Tool\\\\.venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'> top_k_results=3 lang='en' load_all_available_meta=False doc_content_chars_max=4000\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tool.name)\n",
    "print(tool.description)\n",
    "print(tool.args_schema)\n",
    "print(tool.api_wrapper)\n",
    "print(tool.return_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0cfc14e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Vector database\n",
      "Summary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more approximate nearest neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\n",
      "Vectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the complexity of the data being represented. A vector's position in this space represents its characteristics. Words, phrases, or entire documents, as well as images, audio, and other types of data, can all be vectorized.\n",
      "These feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks. The goal is that semantically similar data items receive feature vectors close to each other.\n",
      "Vector databases can be used for similarity search, semantic search, multi-modal search, recommendations engines, large language models (LLMs), object detection,  etc.\n",
      "Vector databases are also often used to implement retrieval-augmented generation (RAG), a method to improve domain-specific responses of large language models. The retrieval component of a RAG can be any search system, but is most often implemented as a vector database. Text documents describing the domain of interest are collected, and for each document or document section, a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database. Given a user prompt, the feature vector of the prompt is computed, and the database is queried to retrieve the most relevant documents. These are then automatically added into the context window of the large language model, and the large language model proceeds to create a response to the prompt given this context.\n",
      "\n",
      "Page: Retrieval-augmented generation\n",
      "Summary: Retrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information. With RAG, LLMs do not respond to user queries until they refer to a specified set of documents. These documents supplement information from the LLM's pre-existing training data. This allows LLMs to use domain-specific and/or updated information that is not available in the training data. For example, this helps LLM-based chatbots access internal company data or generate responses based on authoritative sources.\n",
      "RAG improves large language models (LLMs) by incorporating information retrieval before generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources. According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have caused chatbots to describe policies that don't exist, or recommend nonexistent legal cases to lawyers that are looking for citations to support their arguments.\n",
      "RAG also reduces the need to retrain LLMs with new data, saving on computational and financial costs. Beyond efficiency gains, RAG also allows LLMs to include sources in their responses, so users can verify the cited sources. This provides greater transparency, as \n"
     ]
    }
   ],
   "source": [
    "print(tool.run(\"langchain\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e28fa",
   "metadata": {},
   "source": [
    "### Youtube search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9be20215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9adfb229",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2= YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01c070f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youtube_search\n",
      "search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(tool2.name)\n",
    "print(tool2.description)\n",
    "print(tool2.args)\n",
    "print(tool2.return_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e9ffd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=QWjVEhTiryA&list=RDQWjVEhTiryA&start_radio=1&pp=ygUz4LeD4LazIOC2muC3lOC2uOC3j-C2u-C3kiDgtrjgtpzgt5kg4La44Lax4LeP4La94LeSoAcB', 'https://www.youtube.com/watch?v=xx5NXU8rm14&list=RDxx5NXU8rm14&start_radio=1&pp=ygUz4LeD4LazIOC2muC3lOC2uOC3j-C2u-C3kiDgtrjgtpzgt5kg4La44Lax4LeP4La94LeSoAcB']\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool2.run(\"සඳ කුමාරි මගෙ මනාලි\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50801409",
   "metadata": {},
   "source": [
    "### Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a6ac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer NItro 5\\AppData\\Local\\Temp\\ipykernel_13512\\3023419740.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tool3 = TavilySearchResults()\n"
     ]
    }
   ],
   "source": [
    "tool3 = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9df21230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': '2027 Cricket World Cup - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/2027_Cricket_World_Cup',\n",
       "  'content': \"The Cricket World Cup is a quadrennial One Day International tournament played between men's national cricket teams, organized by the International Cricket Council (ICC). The tournament is held every four years, and was first played in 1975 in England. The last tournament, held in 2023 in India was contested by 10 teams. Australia are the defending champions, having defeated India in the final of the previous edition. [...] |  v  t  e  Cricket World Cup | |\\n --- |\\n| International Cricket Council | |\\n| Tournaments |  England 1975  England 1979  England / Wales 1983  India / Pakistan 1987  Australia / New Zealand 1992  Pakistan / India / Sri Lanka 1996  England / Scotland / Wales / Ireland / Netherlands 1999  South Africa / Zimbabwe / Kenya 2003  West Indies 2007  India / Sri Lanka / Bangladesh 2011  Australia / New Zealand 2015  England / Wales 2019  India 2023  South Africa / Zimbabwe / Namibia 2027 | [...] In November 2021, the ICC announced that the 2027 Cricket World Cup will be played in South Africa, Zimbabwe and Namibia.\\n\\n### Format\",\n",
       "  'score': 0.8036831},\n",
       " {'title': 'Cricket World Cup - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/Cricket_World_Cup',\n",
       "  'content': 'Many of the tournaments have been jointly hosted by nations from the same geographical region, such as South Asia in 1987, 1996 and 2011, Australasia (in Australia and New Zealand) in 1992 and 2015, Southern Africa in 2003 and West Indies in 2007.\\n\\nIn November 2021, ICC published the name of the hosts for ICC events to be played between 2024 and 2031 cycle. The hosts for the 50-over World Cup along with T20 World Cup and Champions Trophy were selected through a competitive bidding process. [...] Australia are the current champions after winning the 2023 World Cup in India. The subsequent 2027 World Cup will be held jointly in South Africa, Zimbabwe and Namibia.\\n\\n## History\\n\\n[edit]\\n\\nMain article: History of the Cricket World Cup [...] ### Hosts triumph (2011–2019)\\n\\n[edit\")]\\n\\nMain articles: 2011 Cricket World Cup, 2015 Cricket World Cup, and 2019 Cricket World Cup',\n",
       "  'score': 0.78866494},\n",
       " {'title': 'Next ICC Tournaments 2025-2031: Schedule, Host Countries and ...',\n",
       "  'url': 'https://www.jagranjosh.com/general-knowledge/upcoming-icc-tournaments-host-country-year-wise-1719992888-1',\n",
       "  'content': \"The ICC Champions Trophy returns in 2025, hosted by Pakistan, featuring the top eight One Day International (ODI) teams.\\n\\nThis period also includes expanded formats for major events: the ICC Men's Cricket World Cup will feature 14 teams in both 2027 and 2031, while the ICC Men's T20 World Cup will see 20 teams competing in 2026, 2028, and 2030. [...] Additionally, the ICC World Test Championship Finals are scheduled for 2025, 2027, 2029, and 2031, highlighting the pinnacle of Test cricket. These tournaments aim to enhance global engagement and showcase the sport's diversity and competitiveness.\\n\\nALSO READ| List Of T20 World Cup Winners Till 2024\\n\\n## Next ICC Tournaments from 2025 to 2031\\n\\nFollowing the thrilling Women's T20 World Cup, the men's team will return to the international stage in the prestigious 2025 Champions Trophy. [...] Scheduled for October-November 2031, the ICC ODI World Cup will be co-hosted by India and Bangladesh. This tournament marks another opportunity for these nations to showcase their love for cricket on an international stage.\\n\\nWith ten teams competing for the prestigious trophy, fans can expect thrilling matches filled with drama and excitement.\\n\\nALSO  READ -\\n\\n T20 World Cup 2024 Prize Money for Winner and Runner-Up\\n Highest Run Scorers of All-Time in International Cricket\\n\\nKriti Barua\",\n",
       "  'score': 0.7653308},\n",
       " {'title': \"ICC Men's T20 Cricket World Cup 2024 full schedule - Olympics.com\",\n",
       "  'url': 'https://www.olympics.com/en/news/t20-cricket-world-cup-2024-schedule-results-scores-standings-full-list',\n",
       "  'content': 'The final – at the Kensington Oval in Barbados on 29 June – came to a nail-biting conclusion with India beating South Africa by seven runs to win their first World Cup title since the inaugural tournament in 2007.\\n\\nThe cricket tournament featured 20 teams for the first time, having expanded from 16, and were split into four groups, with the top two then advancing to the Super 8 round. The Super 8s were made up of two groups, with the top two reaching the semi-finals. [...] Grand Prairie Cricket Stadium, Dallas - Canada 194/5 (20 overs), USA 197/3 (17.4 overs): USA won by 7 wickets\\n\\n### Sunday 2 June\\n\\n Guyana National Stadium, Guyana - Papua New Guinea 136/8 (20 overs), West Indies 137/5 (19 overs): West Indies won by 5 wickets\\n Kensington Oval, Bridgetown, Barbados - Oman 109 (19.4 overs), Namibia 109/6 (20 overs): Match tied (Super Over - Namibia 21/0, Oman 10/1: Namibia won the Super Over)\\n\\n### Monday 3 June [...] Central Broward Park & Broward County Stadium, Lauderhill, Florida - India vs Canada: No result (match abandoned without a ball bowled due to rain)\\n Sir Vivian Richards Stadium, North Sound, Antigua - England 122/5 (10 overs), Namibia 84/3 (10 overs): England won by 41 runs (DLS method)\\n Daren Sammy National Cricket Stadium, Gros Islet, St Lucia - Scotland 180/5 (20 overs), Australia 186/5 (19.4 overs): Australia won by 5 wickets\\n\\n### Sunday 16 June',\n",
       "  'score': 0.6030211},\n",
       " {'title': 'Which countries should host ICC events from 2032-2039? : r/Cricket',\n",
       "  'url': 'https://www.reddit.com/r/Cricket/comments/1b5lsz4/which_countries_should_host_icc_events_from/',\n",
       "  'content': 'These are the countries hosting ICC events from 2023-2031\\n\\nWhich countries should host ICC events for the next 7 years:\\n\\n2035, 2039 ODI World Cups\\n\\n2032, 2034, 2036, 2038 T20 World Cups\\n\\n2033, 2037 Champions Trophy\\n\\n Read more \\n\\n Archived post. New comments cannot be posted and votes cannot be cast. \\n\\n Share \\n\\nRelated Answers Section\\n\\nRelated Answers\\n\\nList of ICC World Cup host countries\\n\\nFuture ICC events and their hosts\\n\\nUpcoming ICC tournaments schedule',\n",
       "  'score': 0.5911811}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool3.invoke({\"query\": \"when is the next cricket world cup?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575e3994",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6018d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59db3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor,create_openai_functions_agent\n",
    "\n",
    "instructions = \"\"\"You are an assistant.\"\"\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)\n",
    "\n",
    "tavily_tool = TavilySearchResults()\n",
    "\n",
    "tools = [tavily_tool]\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "439e1801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'kumar sangakkara'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Kumar Sangakkara - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Kumar_Sangakkara', 'content': 'Kumar Chokshanada Sangakkara (Sinhala: කුමාර් චොක්ශනාද සංගක්කාර; born 27 October 1977) is a Sri Lankan former professional cricketer who represented Sri Lanka from 2000 to 2015. A former captain \"Captain (cricket)\") in all formats, he was born in Matale, Central Province. In first-class cricket, he played for Nondescripts Cricket Club from 1997–98 to 2013–14 and for Surrey County Cricket Club from 2015 to 2017. He was a key part of the Sri Lankan squads which won the 2001-02 Asian Test [...] Sangakkara is a devout Buddhist. He is involved with Sri Lankan charities, mainly those which help children. He is a member of the Think Wise Initiative, which was launched by the ICC in co-operation with UNICEF and the Joint United Nations Programme on HIV/AIDS. It is aimed at raising awareness of HIV prevention and eliminating discrimination against people living with HIV and AIDS. Sangakkara is also a partner in the Foundation of Goodness, a children\\'s charity launched by Muttiah [...] ### Coaching\\n\\n[edit]\\n\\n|  |  |\\n --- |\\n|  | This section needs to be updated. Please help update this article to reflect recent events or newly available information. (September 2023) |\\n\\nSangakkara is the currently the Director of Cricket, Rajasthan Royals in the IPL, having been appointed in January 2021. Under his direction, the Royals reached the 2022 IPL Final but lost by 7 wickets to Gujarat Titans. In IPL 2023, Royals finished fifth in the points table.[citation needed]', 'score': 0.92763275}, {'title': 'History of Kumar sangakkara | Gamers - Vocal Media', 'url': 'https://vocal.media/gamers/history-of-kumar-sangakkara', 'content': \"He captained the Sri Lanka national cricket team in all three formats and is widely regarded as one of the greatest wicket-keeper-batsmen ever and the 2nd highest run scorer of all time. Sangakkara was officially rated in the top three current batsmen in the world in all three formats of the game at various stages of his career. He is the current coach of the Rajasthan Royals IPL team. Sangakkara scored 28,016 runs in international cricket across all formats in a career that spanned 15 years. [...] As a player, Sangakkara was a left-handed top-order brilliant batsman and was also a wicket-keeper for a large proportion of his career. Sangakkara holds many Test records, having been the fastest, or joint-fastest (in terms of innings) to various run milestones in Test cricket. Sangakkara's partnership with Mahela Jayawardene was the second most prolific in the history of Test cricket. Additionally, he holds the record for the most wicket keeping dismissals in ODI cricket. [...] Sangakkara won the ICC Cricketer of the Year in 2012 and won many other awards for both Test and ODI cricket. He was selected as Leading Cricketer in the World in the 2012 and 2015 editions of Wisden Cricketers' Almanack, becoming the second player to have won this award twice. Sangakkara was rated as the Greatest ODI player of all time in a public poll conducted by Cricket Australia in 2016. He won the Man of the Match in the finals of the 2014 ICC World Twenty20 tournament and was part of the\", 'score': 0.7724109}, {'title': 'Kumar Sangakkara Profile - Cricket Player Sri Lanka - ESPNcricinfo', 'url': 'https://www.espncricinfo.com/cricketers/kumar-sangakkara-50710', 'content': \"3 in all forms despite having relinquished the reins in 2011. Sangakkara won the top prize at 2012's ICC awards, in addition to the award for Test Cricketer of\\xa0...Stats·Records·Matches·Videos\", 'score': 0.5923135}, {'title': \"My Lord's Story: Kumar Sangakkara - The Home of Cricket\", 'url': 'https://www.lords.org/lords/news-stories/my-lord-s-story-kumar-sangakkara', 'content': 'Inside I was desperate to get the century and I was always going to be dismissive of that fact in the press, but that was my main objective. In my head I was thinking: \"win the series but also get that hundred\".\\n\\nI worked on my technique, I was ready to make adjustments and I always continued to alter my abilities overnight if I had to.\\n\\nKumar Sangakkara scores a century at Lord\\'s in 2014.\\n\\nKumar Sangakkara scores a century at Lord\\'s in 2014. [...] From making my first international appearance here in 2002 to scoring a Test hundred and now becoming the first overseas President of MCC, the Home of Cricket will always be special to me.\\n\\nMy name is Kumar Sangakkara and this is my Lord’s Story.\\n\\n## My Lord\\'s Story\\n\\n# My Lord\\'s Story | Kapil Dev\\n\\nread story\\n\\n# My Lord\\'s Story | Ross Taylor\\n\\nread story\\n\\n# My Lord\\'s Story | Marcus Trescothick\\n\\nread story\\n\\n© MCC 2025 all rights reserved\\n\\nProudly produced in London [...] My special memory of this place has always been walking through the Long Room, past the Members and seeing the portraits of past players; there’s nothing more special than that.\\n\\nThe history and tradition of the Ground really does stay with you for life.\\n\\nKumar Sangakkara at Lord\\'s in 2019.\\n\\nKumar Sangakkara at Lord\\'s in 2019.\\n\\n2002 was the year that I made my debut here.\\n\\nI remember being hosted for lunch and just the experience of the place, feeling the sense of history, was unbelievable.', 'score': 0.5806618}, {'title': 'Kumar Sangakkara - Biography - IMDb', 'url': 'https://www.imdb.com/name/nm3100551/bio/', 'content': 'Kumar Sangakkara in 2015 Cricket World Cup (2015)\\n\\n# Biography\\n\\n## Kumar Sangakkara\\n\\n### Overview\\n\\n### Biography\\n\\n### Family\\n\\n### Trivia\\n\\n### Contribute to this page\\n\\n### More from this person\\n\\n### More to explore\\n\\n### Recently viewed\\n\\nGet the IMDb App\\n\\n© 1990-2025 by IMDb.com, Inc.', 'score': 0.5009527}]\u001b[0m\u001b[32;1m\u001b[1;3mKumar Chokshanada Sangakkara is a former Sri Lankan cricketer who played internationally from 2000 to 2015.  He was a highly successful left-handed batsman and wicket-keeper, captaining Sri Lanka in all formats of the game.  Considered one of the greatest wicket-keeper-batsmen of all time, he is renowned for his prolific run scoring and holds numerous Test and ODI records.  He's also known for his involvement in charities and currently serves as the Director of Cricket for the Rajasthan Royals in the IPL.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'who was the kumar sangakkara?', 'output': \"Kumar Chokshanada Sangakkara is a former Sri Lankan cricketer who played internationally from 2000 to 2015.  He was a highly successful left-handed batsman and wicket-keeper, captaining Sri Lanka in all formats of the game.  Considered one of the greatest wicket-keeper-batsmen of all time, he is renowned for his prolific run scoring and holds numerous Test and ODI records.  He's also known for his involvement in charities and currently serves as the Director of Cricket for the Rajasthan Royals in the IPL.\"}\n"
     ]
    }
   ],
   "source": [
    "print(agent_executor.invoke({\"input\": \"who was the kumar sangakkara?\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95095d1",
   "metadata": {},
   "source": [
    "## Create custom agent and custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f23c9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\AI\\LangGraph\\AI_Assistant-RAG-Tool\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "101bcd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Look up things online.\"\"\"\n",
    "    return \"LangChain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e38f165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n",
      "Look up things online.\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(search.name)\n",
    "print(search.description)\n",
    "print(search.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ba5434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "293a213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiply two numbers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c28c4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92ff9743",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"search-tool\", args_schema=SearchInput, return_direct=True)\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Look up things online.\"\"\"\n",
    "    return \"LangChain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c19385d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search-tool\n",
      "Look up things online.\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\AI\\LangGraph\\AI_Assistant-RAG-Tool\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='should be a search query' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    }
   ],
   "source": [
    "print(search.name)\n",
    "print(search.description)\n",
    "print(search.args)\n",
    "print(search.return_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b8fb1371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d40bf531",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29d4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "\n",
    "@tool(\"calculator-tool\", args_schema=CalculatorInput, return_direct=True)\n",
    "def calculate(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
